{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monai test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.bundle import ConfigParser, download\n",
    "from monai.transforms import LoadImage, LoadImaged, Orientation, Orientationd, EnsureChannelFirst, EnsureChannelFirstd, Compose\n",
    "from tcia_utils import nbia\n",
    "\n",
    "# Consts.\n",
    "model_name = \"wholeBody_ct_segmentation\"\n",
    "download_model = False\n",
    "data_dir = \"./data\"\n",
    "# dicom_dir = os.path.join(data_dir, \"1.3.6.1.4.1.14519.5.2.1.3320.3273.193828570195012288011029757668\")\n",
    "dicom_dir = os.path.join(data_dir, \"dicom5\")\n",
    "model_path = os.path.join(data_dir, model_name, \"models\", \"model.pt\")\n",
    "config_path = os.path.join(data_dir, model_name, \"configs\", \"inference.json\")\n",
    "simulation_batch_size = 20\n",
    "\n",
    "# Download CT data.\n",
    "print(\"Downloading data\")\n",
    "cart_name = \"nbia-56561691129779503\"\n",
    "cart_data = nbia.getSharedCart(cart_name)\n",
    "df = nbia.downloadSeries(cart_data, format=\"df\", path=data_dir)\n",
    "\n",
    "# Download the model.\n",
    "if download_model:\n",
    "    print(\"Downloading model\")\n",
    "    download(name=model_name, bundle_dir=data_dir)\n",
    "\n",
    "# Get config.\n",
    "# Note: This block of code must occur after the model download block, otherwise config file will not be found.\n",
    "config = ConfigParser()\n",
    "config.read_config(config_path)\n",
    "\n",
    "# Load the model.\n",
    "print(\"Loading model\")\n",
    "torch.cuda.empty_cache()\n",
    "model = config.get_parsed_content(\"network\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "# Get inferer.\n",
    "inferer = config.get_parsed_content(\"inferer\")\n",
    "\n",
    "# Preprocessor for visualization purposes.\n",
    "visualization_preprocessing = Compose([\n",
    "    LoadImaged(keys=\"image\", image_only=True),\n",
    "    EnsureChannelFirstd(keys=\"image\"),\n",
    "    Orientationd(keys=\"image\",axcodes=\"RAS\")\n",
    "])\n",
    "\n",
    "# Preprocessor.\n",
    "preprocessing = config.get_parsed_content(\"preprocessing\")\n",
    "\n",
    "# Postprocessor.\n",
    "postprocessing = config.get_parsed_content(\"postprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization data.\n",
    "visualization_data = {\"image\": dicom_dir}\n",
    "visualization_data = visualization_preprocessing(visualization_data)\n",
    "\n",
    "# Preprocessed data.\n",
    "data = preprocessing({\"image\": dicom_dir})\n",
    "data[\"image\"] = data[\"image\"].unsqueeze(0).cuda()  # Add batch dimension and move to GPU.\n",
    "\n",
    "# Simulate larger batch size.\n",
    "if simulation_batch_size is not None:\n",
    "    data[\"image\"] = data[\"image\"].repeat(simulation_batch_size, 1, 1, 1, 1)\n",
    "\n",
    "print(f\"Image shape: {data['image'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    data[\"pred\"] = inferer(data[\"image\"], network=model)\n",
    "\n",
    "print(f\"Prediction shape: {data['pred'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove batch dimension and move to CPU.\n",
    "data[\"image\"] = data[\"image\"][0].cpu()\n",
    "data[\"pred\"] = data[\"pred\"][0].cpu()\n",
    "\n",
    "# Postprocessing.\n",
    "data = postprocessing(data)\n",
    "\n",
    "# Get segmentation.\n",
    "segmentation = torch.flip(data[\"pred\"][0], dims=[2])\n",
    "segmentation = segmentation.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_index = 10\n",
    "slice = visualization_data[\"image\"][0, :, :, slice_index].numpy()\n",
    "segmentation_slice = segmentation[:, :, slice_index]\n",
    "\n",
    "plt.subplots(1,2,figsize=(6,8))\n",
    "plt.subplot(121)\n",
    "plt.pcolormesh(slice.T, cmap=\"Greys_r\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(122)\n",
    "plt.pcolormesh(segmentation_slice.T, cmap=\"nipy_spectral\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
